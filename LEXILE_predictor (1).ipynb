{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c93MgESnDn"
      },
      "source": [
        " Google Drive 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Vt7QZuM-as",
        "outputId": "cb6824aa-2f53-4ed8-cf30-03ad7297c2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive 마운트 (데이터 파일 접근을 위해)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdwz-V5Tcqu4",
        "outputId": "6d0879f2-7bf8-40d7-c05a-9e75a22b7e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# 1. 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import shutil\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSVdg8nWZ2Xt",
        "outputId": "18188904-d0ad-45b0-b511-183265f7a47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Index(['lexile', 'text'], dtype='object')\n",
            "   lexile                                               text\n",
            "0    1100  International scam artists use clever schemes ...\n",
            "1    1140  A critical election loomed. The country was de...\n",
            "2     810  It was a beautiful night in late August. We we...\n",
            "3     700  As Angela stared out the school bus window, he...\n",
            "4    1110  In the 1950s and 1960s, racial conflicts were ...\n"
          ]
        }
      ],
      "source": [
        "# 2. 데이터 로드 및 전처리\n",
        "# 데이터 경로 설정 (Google Drive에 있는 파일 경로)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/na_rm data.csv'\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# 데이터 구조 확인\n",
        "print(data.columns)\n",
        "print(data.head())\n",
        "\n",
        "# 결측치가 있는 행 제거\n",
        "data = data.dropna(subset=['lexile', 'text'])\n",
        "\n",
        "# 텍스트와 레이블 분리\n",
        "texts = data['text'].tolist()\n",
        "lexile_scores = data['lexile'].tolist()\n",
        "\n",
        "# Lexile 점수를 8개의 범주로 나누기\n",
        "bins = [0, 630, 760, 850, 930, 990, 1120, 1300, float('inf')]\n",
        "labels = list(range(8))  # 0, 1, 2, 3, 4, 5, 6, 7\n",
        "lexile_categories = pd.cut(lexile_scores, bins=bins, labels=labels)\n",
        "\n",
        "# 범주형 데이터를 정수로 변환\n",
        "lexile_categories = lexile_categories.astype(int).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u4dJYcYWe3P"
      },
      "outputs": [],
      "source": [
        "# 3. 데이터셋 클래스 정의\n",
        "class LexileDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # 토큰화\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # 텐서로 변환\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8EgXiD7dFWm"
      },
      "outputs": [],
      "source": [
        "# 4. 토크나이저 로드 및 데이터셋 생성\n",
        "# BERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Train/Test Split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, lexile_categories, test_size=0.2, random_state=42)\n",
        "\n",
        "# 커스텀 데이터셋 생성\n",
        "train_dataset = LexileDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = LexileDataset(val_texts, val_labels, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhaVCyOBdHn_",
        "outputId": "5b12d9db-9c6c-4e79-d856-5a99c2df6588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 5. 모델 및 학습 설정\n",
        "# BERT 모델 및 분류기 Head 정의\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
        "model.to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output 디렉터리\n",
        "    evaluation_strategy=\"epoch\",   # 매 에폭마다 평가\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',            # 로그 디렉터리\n",
        "    logging_steps=10,                # 로그 출력 주기\n",
        "    report_to=\"tensorboard\"         # 로그 활성화\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "JnksJoxwdIYj",
        "outputId": "2d98af50-e5ef-4f50-d88a-b56b03a74b0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='246' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [246/246 05:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.867000</td>\n",
              "      <td>1.781707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.630200</td>\n",
              "      <td>1.519786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.425400</td>\n",
              "      <td>1.472857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=246, training_loss=1.6949927613018005, metrics={'train_runtime': 315.8836, 'train_samples_per_second': 12.327, 'train_steps_per_second': 0.779, 'total_flos': 512304821968896.0, 'train_loss': 1.6949927613018005, 'epoch': 3.0})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. 모델 학습\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "yPlz3wXtdLq0",
        "outputId": "708fe296-ef76-4454-87b6-36d9c724eb79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 00:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.4728572368621826,\n",
              " 'eval_runtime': 13.4613,\n",
              " 'eval_samples_per_second': 24.143,\n",
              " 'eval_steps_per_second': 1.56,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. 모델 평가\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "8vQXbwYVdPTg",
        "outputId": "37b478d5-fe04-4c76-e07d-89a0396fd44c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6903af380511>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0man\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m \u001b[0mto\u001b[0m \u001b[0mhear\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mhe\u001b[0m \u001b[0mhad\u001b[0m \u001b[0mto\u001b[0m \u001b[0msay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m '''\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# 모델 디바이스에 맞춰 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "# 8. 새로운 텍스트 예측\n",
        "test_text = '''\n",
        "As soon as the light in the bedroom went out there was a stirring and a\n",
        "fluttering all through the farm buildings. Word had gone round during the\n",
        "day that old Major, the prize Middle White boar, had had a strange dream\n",
        "on the previous night and wished to communicate it to the other animals.\n",
        "It had been agreed that they should all meet in the big barn as soon as\n",
        "Mr. Jones was safely out of the way. Old Major (so he was always called,\n",
        "though the name under which he had been exhibited was Willingdon Beauty)\n",
        "was so highly regarded on the farm that everyone was quite ready to lose\n",
        "an hour's sleep in order to hear what he had to say.\n",
        "'''\n",
        "encoded_input = tokenizer(test_text, return_tensors='pt', padding='max_length', truncation=True, max_length=256)\n",
        "encoded_input = {key: val.to(device) for key, val in encoded_input.items()}  # 모델 디바이스에 맞춰 이동\n",
        "output = model(**encoded_input)\n",
        "predicted_label = torch.argmax(output.logits, dim=1)\n",
        "\n",
        "# 범주형 레이블에 따른 Lexile 레벨 출력\n",
        "categories = {\n",
        "    0: \"0-630 (0%-10%)\",\n",
        "    1: \"631-760 (10%-20%)\",\n",
        "    2: \"761-850 (20%-30%)\",\n",
        "    3: \"851-930 (30%-40%)\",\n",
        "    4: \"931-990 (40%-50%)\",\n",
        "    5: \"991-1120 (50%-70%)\",\n",
        "    6: \"1121-1300 (70%-90%)\",\n",
        "    7: \"1301-2650 (90%-100%)\"\n",
        "}\n",
        "print(f\"Predicted Lexile Level: {categories[predicted_label.item()]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hyi0sMF6eMeK",
        "outputId": "1f9820bd-15f8-44dd-d09f-ac56bd7a6332"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_709e3d07-7a00-4189-ab7f-84fd7e7c668e\", \"saved_model.zip\", 405710616)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 9. 학습된 모델 저장 및 다운로드\n",
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')\n",
        "\n",
        "# Google Colab을 통한 파일 다운로드\n",
        "from google.colab import files\n",
        "shutil.make_archive('saved_model', 'zip', './saved_model')\n",
        "files.download('saved_model.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}