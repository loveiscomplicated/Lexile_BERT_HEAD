{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c93MgESnDn"
      },
      "source": [
        " Google Drive ë§ˆìš´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Vt7QZuM-as",
        "outputId": "cb6824aa-2f53-4ed8-cf30-03ad7297c2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive ë§ˆìš´íŠ¸ (ë°ì´í„° íŒŒì¼ ì ‘ê·¼ì„ ìœ„í•´)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdwz-V5Tcqu4",
        "outputId": "6d0879f2-7bf8-40d7-c05a-9e75a22b7e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import shutil\n",
        "\n",
        "# GPU ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSVdg8nWZ2Xt",
        "outputId": "18188904-d0ad-45b0-b511-183265f7a47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Index(['lexile', 'text'], dtype='object')\n",
            "   lexile                                               text\n",
            "0    1100  International scam artists use clever schemes ...\n",
            "1    1140  A critical election loomed. The country was de...\n",
            "2     810  It was a beautiful night in late August. We we...\n",
            "3     700  As Angela stared out the school bus window, he...\n",
            "4    1110  In the 1950s and 1960s, racial conflicts were ...\n"
          ]
        }
      ],
      "source": [
        "# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "# ë°ì´í„° ê²½ë¡œ ì„¤ì • (Google Driveì— ìˆëŠ” íŒŒì¼ ê²½ë¡œ)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/na_rm data.csv'\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "print(data.columns)\n",
        "print(data.head())\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì œê±°\n",
        "data = data.dropna(subset=['lexile', 'text'])\n",
        "\n",
        "# í…ìŠ¤íŠ¸ì™€ ë ˆì´ë¸” ë¶„ë¦¬\n",
        "texts = data['text'].tolist()\n",
        "lexile_scores = data['lexile'].tolist()\n",
        "\n",
        "# Lexile ì ìˆ˜ë¥¼ 8ê°œì˜ ë²”ì£¼ë¡œ ë‚˜ëˆ„ê¸°\n",
        "bins = [0, 630, 760, 850, 930, 990, 1120, 1300, float('inf')]\n",
        "labels = list(range(8))  # 0, 1, 2, 3, 4, 5, 6, 7\n",
        "lexile_categories = pd.cut(lexile_scores, bins=bins, labels=labels)\n",
        "\n",
        "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜\n",
        "lexile_categories = lexile_categories.astype(int).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u4dJYcYWe3P"
      },
      "outputs": [],
      "source": [
        "# 3. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
        "class LexileDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # í† í°í™”\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # í…ì„œë¡œ ë³€í™˜\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8EgXiD7dFWm"
      },
      "outputs": [],
      "source": [
        "# 4. í† í¬ë‚˜ì´ì € ë¡œë“œ ë° ë°ì´í„°ì…‹ ìƒì„±\n",
        "# BERT í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Train/Test Split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, lexile_categories, test_size=0.2, random_state=42)\n",
        "\n",
        "# ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ìƒì„±\n",
        "train_dataset = LexileDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = LexileDataset(val_texts, val_labels, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhaVCyOBdHn_",
        "outputId": "5b12d9db-9c6c-4e79-d856-5a99c2df6588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 5. ëª¨ë¸ ë° í•™ìŠµ ì„¤ì •\n",
        "# BERT ëª¨ë¸ ë° ë¶„ë¥˜ê¸° Head ì •ì˜\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
        "model.to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output ë””ë ‰í„°ë¦¬\n",
        "    evaluation_strategy=\"epoch\",   # ë§¤ ì—í­ë§ˆë‹¤ í‰ê°€\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',            # ë¡œê·¸ ë””ë ‰í„°ë¦¬\n",
        "    logging_steps=10,                # ë¡œê·¸ ì¶œë ¥ ì£¼ê¸°\n",
        "    report_to=\"tensorboard\"         # ë¡œê·¸ í™œì„±í™”\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "JnksJoxwdIYj",
        "outputId": "2d98af50-e5ef-4f50-d88a-b56b03a74b0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='246' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [246/246 05:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.867000</td>\n",
              "      <td>1.781707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.630200</td>\n",
              "      <td>1.519786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.425400</td>\n",
              "      <td>1.472857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=246, training_loss=1.6949927613018005, metrics={'train_runtime': 315.8836, 'train_samples_per_second': 12.327, 'train_steps_per_second': 0.779, 'total_flos': 512304821968896.0, 'train_loss': 1.6949927613018005, 'epoch': 3.0})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. ëª¨ë¸ í•™ìŠµ\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "yPlz3wXtdLq0",
        "outputId": "708fe296-ef76-4454-87b6-36d9c724eb79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 00:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.4728572368621826,\n",
              " 'eval_runtime': 13.4613,\n",
              " 'eval_samples_per_second': 24.143,\n",
              " 'eval_steps_per_second': 1.56,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. ëª¨ë¸ í‰ê°€\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "8vQXbwYVdPTg",
        "outputId": "37b478d5-fe04-4c76-e07d-89a0396fd44c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6903af380511>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0man\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m \u001b[0mto\u001b[0m \u001b[0mhear\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mhe\u001b[0m \u001b[0mhad\u001b[0m \u001b[0mto\u001b[0m \u001b[0msay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m '''\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# ëª¨ë¸ ë””ë°”ì´ìŠ¤ì— ë§ì¶° ì´ë™\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "# 8. ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ì˜ˆì¸¡\n",
        "test_text = '''\n",
        "As soon as the light in the bedroom went out there was a stirring and a\n",
        "fluttering all through the farm buildings. Word had gone round during the\n",
        "day that old Major, the prize Middle White boar, had had a strange dream\n",
        "on the previous night and wished to communicate it to the other animals.\n",
        "It had been agreed that they should all meet in the big barn as soon as\n",
        "Mr. Jones was safely out of the way. Old Major (so he was always called,\n",
        "though the name under which he had been exhibited was Willingdon Beauty)\n",
        "was so highly regarded on the farm that everyone was quite ready to lose\n",
        "an hour's sleep in order to hear what he had to say.\n",
        "'''\n",
        "encoded_input = tokenizer(test_text, return_tensors='pt', padding='max_length', truncation=True, max_length=256)\n",
        "encoded_input = {key: val.to(device) for key, val in encoded_input.items()}  # ëª¨ë¸ ë””ë°”ì´ìŠ¤ì— ë§ì¶° ì´ë™\n",
        "output = model(**encoded_input)\n",
        "predicted_label = torch.argmax(output.logits, dim=1)\n",
        "\n",
        "# ë²”ì£¼í˜• ë ˆì´ë¸”ì— ë”°ë¥¸ Lexile ë ˆë²¨ ì¶œë ¥\n",
        "categories = {\n",
        "    0: \"0-630 (0%-10%)\",\n",
        "    1: \"631-760 (10%-20%)\",\n",
        "    2: \"761-850 (20%-30%)\",\n",
        "    3: \"851-930 (30%-40%)\",\n",
        "    4: \"931-990 (40%-50%)\",\n",
        "    5: \"991-1120 (50%-70%)\",\n",
        "    6: \"1121-1300 (70%-90%)\",\n",
        "    7: \"1301-2650 (90%-100%)\"\n",
        "}\n",
        "print(f\"Predicted Lexile Level: {categories[predicted_label.item()]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hyi0sMF6eMeK",
        "outputId": "1f9820bd-15f8-44dd-d09f-ac56bd7a6332"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_709e3d07-7a00-4189-ab7f-84fd7e7c668e\", \"saved_model.zip\", 405710616)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 9. í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')\n",
        "\n",
        "# Google Colabì„ í†µí•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "from google.colab import files\n",
        "shutil.make_archive('saved_model', 'zip', './saved_model')\n",
        "files.download('saved_model.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}